{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOhdkfuLIMKbBcjb5nsZ8Pr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"rpa6ubvPl6wa","executionInfo":{"status":"ok","timestamp":1757052199690,"user_tz":-330,"elapsed":8295,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"00fe5624-5e5c-43e9-98e9-985293acffce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","source":["!rm -rf /content/id_docs_resized\n","!rm -rf /content/my_dataset/"],"metadata":{"id":"zK3dK6MMnaDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RJ-5hSuZbXq"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import MobileNetV2\n","import os\n","import shutil"]},{"cell_type":"code","source":["!apt-get install -y unrar\n","!unrar x /content/id_docs_resized_224_nic.rar /content/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"G0tdO26NdaMQ","executionInfo":{"status":"ok","timestamp":1757052244668,"user_tz":-330,"elapsed":2850,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"4e866992-4106-4cbc-df65-b63454b0f782"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","unrar is already the newest version (1:6.1.5-1ubuntu0.1).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n","\n","UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n","\n","\n","Extracting from /content/id_docs_resized_224_nic.rar\n","\n","Creating    /content/id_docs_resized                                  OK\n","Creating    /content/id_docs_resized/train                            OK\n","Creating    /content/id_docs_resized/train/old_nic                    OK\n","Extracting  /content/id_docs_resized/train/old_nic/image_1.jpg           \b\b\b\b  0%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_10.jpeg         \b\b\b\b  0%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_100.jpg         \b\b\b\b  1%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_101.jpeg        \b\b\b\b  2%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_102.jpeg        \b\b\b\b  2%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_103.jpeg        \b\b\b\b  3%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_104.jpeg        \b\b\b\b  3%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_105.jpeg        \b\b\b\b  3%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_106.jpeg        \b\b\b\b  4%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_107.jpeg        \b\b\b\b  4%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_108.jpeg        \b\b\b\b  4%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_109.jpg         \b\b\b\b  5%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_11.jpeg         \b\b\b\b  6%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_110.jpg         \b\b\b\b  6%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_111.jpg         \b\b\b\b  7%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_112.jpg         \b\b\b\b  7%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_113.jpg         \b\b\b\b  8%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_114.jpg         \b\b\b\b  9%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_115.jpg         \b\b\b\b  9%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_116.jpg         \b\b\b\b 10%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_117.jpg         \b\b\b\b 11%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_118.jpg         \b\b\b\b 11%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_119.jpg         \b\b\b\b 12%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_12.jpeg         \b\b\b\b 12%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_120.jpg         \b\b\b\b 13%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_121.jpg         \b\b\b\b 13%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_122.jpg         \b\b\b\b 13%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_123.jpg         \b\b\b\b 14%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_124.jpg         \b\b\b\b 14%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_125.jpg         \b\b\b\b 15%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_126.jpg         \b\b\b\b 16%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_127.jpg         \b\b\b\b 16%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_128.jpg         \b\b\b\b 17%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_129.jpg         \b\b\b\b 17%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_13.jpg          \b\b\b\b 18%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_130.jpg         \b\b\b\b 18%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_131.jpg         \b\b\b\b 19%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_132.jpg         \b\b\b\b 19%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_133.jpg         \b\b\b\b 20%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_134.jpg         \b\b\b\b 20%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_135.jpg         \b\b\b\b 21%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_136.jpg         \b\b\b\b 21%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_137.jpg         \b\b\b\b 22%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_138.jpg         \b\b\b\b 23%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_139.jpg         \b\b\b\b 23%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_14.jpg          \b\b\b\b 24%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_140.jpg         \b\b\b\b 24%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_141.jpg         \b\b\b\b 25%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_142.jpg         \b\b\b\b 25%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_143.jpg         \b\b\b\b 26%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_144.jpg         \b\b\b\b 26%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_145.jpg         \b\b\b\b 27%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_146.jpg         \b\b\b\b 27%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_147.jpg         \b\b\b\b 28%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_148.jpg         \b\b\b\b 28%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_149.jpg         \b\b\b\b 29%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_15.jpg          \b\b\b\b 30%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_150.jpg         \b\b\b\b 30%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_151.jpg         \b\b\b\b 31%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_152.jpg         \b\b\b\b 31%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_153.jpg         \b\b\b\b 32%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_154.jpg         \b\b\b\b 32%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_155.jpg         \b\b\b\b 33%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_156.jpg         \b\b\b\b 34%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_157.jpg         \b\b\b\b 34%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_158.jpg         \b\b\b\b 35%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_159.jpg         \b\b\b\b 35%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_16.jpg          \b\b\b\b 36%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_160.jpg         \b\b\b\b 36%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_161.jpg         \b\b\b\b 37%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_162.jpg         \b\b\b\b 37%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_163.jpg         \b\b\b\b 38%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_164.jpg         \b\b\b\b 38%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_165.jpeg        \b\b\b\b 39%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_166.jpeg        \b\b\b\b 39%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_167.jpeg        \b\b\b\b 40%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_168.jpeg        \b\b\b\b 41%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_169.jpeg        \b\b\b\b 41%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_17.jpeg         \b\b\b\b 42%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_170.jpeg        \b\b\b\b 42%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_171.jpeg        \b\b\b\b 43%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_172.jpeg        \b\b\b\b 43%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_18.jpeg         \b\b\b\b 44%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_19.jpeg         \b\b\b\b 44%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_2.jpg           \b\b\b\b 45%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_20.jpeg         \b\b\b\b 45%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_21.jpeg         \b\b\b\b 46%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_22.jpeg         \b\b\b\b 46%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_23.jpeg         \b\b\b\b 47%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_24.jpeg         \b\b\b\b 48%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_25.jpeg         \b\b\b\b 48%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_26.jpeg         \b\b\b\b 49%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_27.jpeg         \b\b\b\b 49%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_28.jpeg         \b\b\b\b 50%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_29.jpeg         \b\b\b\b 50%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_3.jpg           \b\b\b\b 51%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_30.jpeg         \b\b\b\b 51%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_31.jpeg         \b\b\b\b 52%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_32.jpeg         \b\b\b\b 52%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_33.jpeg         \b\b\b\b 53%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_34.jpeg         \b\b\b\b 53%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_35.jpeg         \b\b\b\b 54%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_36.jpeg         \b\b\b\b 54%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_37.jpeg         \b\b\b\b 55%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_38.jpeg         \b\b\b\b 55%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_39.jpeg         \b\b\b\b 56%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_4.jpg           \b\b\b\b 56%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_40.jpeg         \b\b\b\b 57%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_41.jpeg         \b\b\b\b 57%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_42.jpeg         \b\b\b\b 58%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_43.jpeg         \b\b\b\b 58%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_44.jpeg         \b\b\b\b 59%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_45.jpeg         \b\b\b\b 59%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_46.jpeg         \b\b\b\b 60%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_47.jpeg         \b\b\b\b 60%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_48.jpeg         \b\b\b\b 61%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_49.jpeg         \b\b\b\b 61%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_5.jpeg          \b\b\b\b 62%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_50.jpeg         \b\b\b\b 63%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_51.jpeg         \b\b\b\b 63%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_52.jpeg         \b\b\b\b 64%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_53.jpeg         \b\b\b\b 65%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_54.jpeg         \b\b\b\b 65%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_55.jpeg         \b\b\b\b 66%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_56.jpeg         \b\b\b\b 67%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_57.jpeg         \b\b\b\b 68%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_58.jpeg         \b\b\b\b 68%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_59.jpeg         \b\b\b\b 69%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_6.jpeg          \b\b\b\b 70%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_60.jpeg         \b\b\b\b 70%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_61.jpeg         \b\b\b\b 71%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_62.jpeg         \b\b\b\b 71%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_63.jpeg         \b\b\b\b 72%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_64.jpeg         \b\b\b\b 73%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_65.jpeg         \b\b\b\b 73%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_66.jpeg         \b\b\b\b 74%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_67.jpeg         \b\b\b\b 75%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_68.jpeg         \b\b\b\b 75%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_69.jpeg         \b\b\b\b 76%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_7.jpeg          \b\b\b\b 77%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_70.jpeg         \b\b\b\b 77%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_71.jpeg         \b\b\b\b 78%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_72.jpeg         \b\b\b\b 79%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_73.jpeg         \b\b\b\b 79%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_74.jpeg         \b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_75.jpeg         \b\b\b\b 81%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_76.jpeg         \b\b\b\b 81%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_77.jpeg         \b\b\b\b 82%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_78.jpeg         \b\b\b\b 83%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_79.jpeg         \b\b\b\b 83%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_8.jpeg          \b\b\b\b 84%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_80.jpeg         \b\b\b\b 85%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_81.jpeg         \b\b\b\b 85%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_82.jpeg         \b\b\b\b 86%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_83.jpeg         \b\b\b\b 86%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_84.jpeg         \b\b\b\b 87%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_85.jpeg         \b\b\b\b 87%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_86.jpeg         \b\b\b\b 88%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_87.jpeg         \b\b\b\b 89%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_88.jpeg         \b\b\b\b 89%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_89.jpeg         \b\b\b\b 90%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_9.jpeg          \b\b\b\b 91%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_90.jpeg         \b\b\b\b 91%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_91.jpeg         \b\b\b\b 92%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_92.jpeg         \b\b\b\b 92%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_93.jpeg         \b\b\b\b 93%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_94.jpeg         \b\b\b\b 94%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_95.jpeg         \b\b\b\b 94%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_96.jpeg         \b\b\b\b 95%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_97.jpg          \b\b\b\b 95%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_98.jpg          \b\b\b\b 96%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/train/old_nic/image_99.jpg          \b\b\b\b 96%\b\b\b\b\b  OK \n","Creating    /content/id_docs_resized/validation                       OK\n","Creating    /content/id_docs_resized/validation/old_nic               OK\n","Extracting  /content/id_docs_resized/validation/old_nic/image_28.jpg     \b\b\b\b 98%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/validation/old_nic/image_41.jpg     \b\b\b\b 98%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/validation/old_nic/image_42.jpeg     \b\b\b\b 99%\b\b\b\b\b  OK \n","Extracting  /content/id_docs_resized/validation/old_nic/image_43.jpeg     \b\b\b\b 99%\b\b\b\b\b  OK \n","All OK\n"]}]},{"cell_type":"code","source":["DATASET_PATH = 'id_docs_resized'\n","IMAGE_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 20\n","LEARNING_RATE = 0.0001\n","VALIDATION_SPLIT = 0.2"],"metadata":{"id":"_QFPHF1KmT5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if the dataset path exists\n","if not os.path.exists(DATASET_PATH):\n","    print(f\"Error: Dataset directory '{DATASET_PATH}' not found.\")\n","    print(\"Please create the directory with a 'train' and 'validation' subfolder,\")\n","    print(\"and place your images in category-specific subfolders.\")\n","    exit()"],"metadata":{"id":"Y32eC2DLmcvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Data Augmentation and Loading ---\n","# We use data augmentation to create more training examples from a small dataset.\n","# This helps the model generalize better and reduces overfitting.\n","train_datagen = image.ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    validation_split=VALIDATION_SPLIT\n",")"],"metadata":{"id":"Eppi3DJ3mhW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["validation_datagen = image.ImageDataGenerator(rescale=1./255)"],"metadata":{"id":"W02cww6bmj4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the training and validation data from the directory\n","print(\"Loading training data...\")\n","train_generator = train_datagen.flow_from_directory(\n","    os.path.join(DATASET_PATH, 'train'),\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='training'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFiSu3UfmnFX","executionInfo":{"status":"ok","timestamp":1757052264947,"user_tz":-330,"elapsed":10,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"50d1f8bc-3f75-4a8a-9305-3669e84b4428"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading training data...\n","Found 138 images belonging to 1 classes.\n"]}]},{"cell_type":"code","source":["print(\"\\nLoading validation data...\")\n","validation_generator = train_datagen.flow_from_directory(\n","    os.path.join(DATASET_PATH, 'train'),\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='validation'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7N49A3f0mqwj","executionInfo":{"status":"ok","timestamp":1757052267647,"user_tz":-330,"elapsed":6,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"e3d342e3-2b58-439a-c6d1-65cc4435fbac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Loading validation data...\n","Found 34 images belonging to 1 classes.\n"]}]},{"cell_type":"code","source":["# Get the number of classes from the generator\n","num_classes = train_generator.num_classes\n","class_names = list(train_generator.class_indices.keys())\n","print(f\"\\nFound {num_classes} classes: {class_names}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ex-O_LePms-p","executionInfo":{"status":"ok","timestamp":1757052270067,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"52d6136c-817e-4d18-8978-3f26e5a18fea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Found 1 classes: ['old_nic']\n"]}]},{"cell_type":"code","source":["# --- Build the Model with Transfer Learning ---\n","# Load the pre-trained MobileNetV2 model without the top classification layers.\n","base_model = MobileNetV2(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJ_A3NHEnzHg","executionInfo":{"status":"ok","timestamp":1757052276351,"user_tz":-330,"elapsed":2838,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"e69bd2df-20cb-49c0-a338-f969a65123ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# Freeze the convolutional base\n","base_model.trainable = False\n","print(\"\\nBase MobileNetV2 model loaded and frozen.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2i1G8wZCn9cM","executionInfo":{"status":"ok","timestamp":1757052300777,"user_tz":-330,"elapsed":49,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"6c818499-3445-4460-c305-c7462a991b67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Base MobileNetV2 model loaded and frozen.\n"]}]},{"cell_type":"code","source":["# Create the new model on top of the base model\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),  # Reduces the spatial dimensions of the feature maps\n","    Dense(512, activation='relu'),\n","    Dropout(0.5), # Add dropout to prevent overfitting\n","    Dense(num_classes, activation='softmax') # The final classification layer\n","])"],"metadata":{"id":"1wpsCAIpn_hU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Compile and Train the Model ---\n","print(\"\\nCompiling model...\")\n","model.compile(\n","    optimizer=Adam(learning_rate=LEARNING_RATE),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nt8IMANcoEAy","executionInfo":{"status":"ok","timestamp":1757052305147,"user_tz":-330,"elapsed":14,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"a0aa814b-a27d-42d8-9359-6e996ec7c1c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Compiling model...\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"9Q5iDEX1oLz3","executionInfo":{"status":"ok","timestamp":1757052314690,"user_tz":-330,"elapsed":54,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"efcfcecc-0dab-41a4-d2dd-433f355cc08f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m655,872\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,914,369\u001b[0m (11.12 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,914,369</span> (11.12 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m656,385\u001b[0m (2.50 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">656,385</span> (2.50 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["print(\"\\nTraining model...\")\n","history = model.fit(\n","    train_generator,\n","    epochs=NUM_EPOCHS,\n","    validation_data=validation_generator,\n","    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n","    validation_steps=validation_generator.samples // BATCH_SIZE\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IbG3HnaotmD","executionInfo":{"status":"ok","timestamp":1757052397744,"user_tz":-330,"elapsed":73992,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"13ce0ed7-0076-4dcc-a562-66bcec0f5381"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n","  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 2/20\n","\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0000e+00"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self._interrupted_warning()\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 785ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 3/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 644ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 4/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 5/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 6/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 7/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 724ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 8/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 9/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 811ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 10/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 11/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 867ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 12/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 13/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 14/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 15/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 574ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 16/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 17/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 911ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 18/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 19/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 970ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n","Epoch 20/20\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"]}]},{"cell_type":"code","source":["# --- Save the Model ---\n","model.save('image_classifier_transfer_learning.h5')\n","print(\"\\nModel saved to 'image_classifier_transfer_learning.h5'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcA_61YPov6K","executionInfo":{"status":"ok","timestamp":1757052401223,"user_tz":-330,"elapsed":287,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"2af7f5c0-b856-4a31-d1ae-3d104f24ba58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\n","Model saved to 'image_classifier_transfer_learning.h5'\n"]}]},{"cell_type":"code","source":["# --- Predict a new image (Example) ---\n","def predict_image(model, img_path):\n","    img = image.load_img(img_path, target_size=IMAGE_SIZE)\n","    img_array = image.img_to_array(img)\n","    img_array = tf.expand_dims(img_array, 0) # Create a batch\n","    img_array = img_array / 255.0 # Rescale the pixel values\n","\n","    predictions = model.predict(img_array)\n","    predicted_class_index = tf.argmax(predictions[0])\n","    predicted_class = class_names[predicted_class_index]\n","    confidence = tf.reduce_max(predictions[0]) * 100\n","\n","    print(f\"\\nPrediction for {img_path}:\")\n","    print(f\"Predicted class: {predicted_class}\")\n","    print(f\"Confidence: {confidence.numpy():.2f}%\")"],"metadata":{"id":"Lm8uCFzvo3ti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_image(model, 'cake.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGt_x8RAo7dJ","executionInfo":{"status":"ok","timestamp":1757052456104,"user_tz":-330,"elapsed":10309,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"53c33daf-8de4-4683-b0a8-00f7e659259d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n","\n","Prediction for cake.jpg:\n","Predicted class: old_nic\n","Confidence: 100.00%\n"]}]},{"cell_type":"code","source":["predict_image(model, 'id_docs_resized/validation/new_nic/image_11.jpg')\n","predict_image(model, 'id_docs_resized/validation/new_nic/image_12.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3IN1zZzpJIi","executionInfo":{"status":"ok","timestamp":1757004989193,"user_tz":-330,"elapsed":179,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"12c26b36-d066-40d8-804a-7193717c4d40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","Prediction for id_docs_resized/validation/new_nic/image_11.jpg:\n","Predicted class: new_nic\n","Confidence: 55.08%\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","Prediction for id_docs_resized/validation/new_nic/image_12.jpg:\n","Predicted class: new_nic\n","Confidence: 42.98%\n"]}]},{"cell_type":"code","source":["predict_image(model, 'id_docs_resized/validation/old_nic/image_41.jpg')\n","predict_image(model, 'id_docs_resized/validation/old_nic/image_42.jpeg')\n","predict_image(model, 'id_docs_resized/validation/old_nic/image_43.jpeg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfGbStRSpO9Z","executionInfo":{"status":"ok","timestamp":1757005025724,"user_tz":-330,"elapsed":213,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"6c2bb382-c7fb-4eef-bf2d-e357ad03465c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\n","Prediction for id_docs_resized/validation/old_nic/image_41.jpg:\n","Predicted class: old_nic\n","Confidence: 97.25%\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\n","Prediction for id_docs_resized/validation/old_nic/image_42.jpeg:\n","Predicted class: old_nic\n","Confidence: 97.06%\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","Prediction for id_docs_resized/validation/old_nic/image_43.jpeg:\n","Predicted class: old_nic\n","Confidence: 98.34%\n"]}]},{"cell_type":"code","source":["predict_image(model, 'id_docs_resized/validation/passport/image_10.jpg')\n","predict_image(model, 'id_docs_resized/validation/passport/image_9.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBempN3Rpuwq","executionInfo":{"status":"ok","timestamp":1757005077026,"user_tz":-330,"elapsed":242,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"e5253f25-206f-4c95-c2ce-b8c380841caa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\n","Prediction for id_docs_resized/validation/passport/image_10.jpg:\n","Predicted class: passport\n","Confidence: 82.59%\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\n","Prediction for id_docs_resized/validation/passport/image_9.jpg:\n","Predicted class: passport\n","Confidence: 63.50%\n"]}]},{"cell_type":"code","source":["#random image\n","predict_image(model, 'cake.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"-hyjJfwyreZj","executionInfo":{"status":"error","timestamp":1757061557217,"user_tz":-330,"elapsed":24,"user":{"displayName":"Arvin Jayanake","userId":"09599054493066328195"}},"outputId":"cad55b1b-3cdd-4e8e-d4b6-e55278e94e96"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'predict_image' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2157186934.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#random image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cake.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'predict_image' is not defined"]}]}]}