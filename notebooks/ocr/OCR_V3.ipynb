{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "4MVXX6_SO6u0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfXTFn6fNW8H",
        "outputId": "7cd56408-fc01-41be-ff7e-1563cd7c840d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Colab/TF setup\n",
        "import os, sys, zipfile, tarfile, random, math, io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "device_names = tf.config.list_physical_devices()\n",
        "print(\"Devices:\", device_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get IIIT-5K and read annotations"
      ],
      "metadata": {
        "id": "DMRQQGryPt_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download IIIT-5K (official mirror)\n",
        "!wget -O IIIT5K.tar.gz https://cvit.iiit.ac.in/images/Projects/SceneTextUnderstanding/IIIT5K-Word_V3.0.tar.gz\n",
        "!mkdir -p IIIT5K && tar -xzf IIIT5K.tar.gz -C IIIT5K --strip-components=1\n",
        "\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# .mat files are now directly in IIIT5K/\n",
        "train_mat = sio.loadmat(os.path.join(\"IIIT5K\", \"trainCharBound.mat\"))\n",
        "test_mat = sio.loadmat(os.path.join(\"IIIT5K\", \"testCharBound.mat\"))\n",
        "\n",
        "def load_split(mat_key, base_dir=\"IIIT5K\"):\n",
        "    struct = None\n",
        "    # Find the structured array in the .mat file\n",
        "    for key in mat_key:\n",
        "        if isinstance(mat_key[key], np.ndarray) and mat_key[key].dtype.names:\n",
        "            struct = mat_key[key]\n",
        "            break\n",
        "    if struct is None:\n",
        "        raise ValueError(\"Structured array not found in .mat file\")\n",
        "\n",
        "    images, labels = [], []\n",
        "    for item in struct[0]:\n",
        "        fname = item['ImgName'][0]  # e.g., 'train/123_1.png'\n",
        "        text = item['chars'][0]     # ground truth word\n",
        "        images.append(os.path.join(base_dir, fname))\n",
        "        labels.append(str(text))\n",
        "    return images, labels\n",
        "\n",
        "train_images, train_labels = load_split(train_mat, \"IIIT5K\")\n",
        "test_images, test_labels = load_split(test_mat, \"IIIT5K\")\n",
        "\n",
        "print(len(train_images), \"train |\", len(test_images), \"test\")\n",
        "print(train_images[0], \"->\", train_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5gkqOKyO8Nn",
        "outputId": "0e2d024a-c6dc-48cc-bced-7e85db5d258d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-29 10:28:43--  https://cvit.iiit.ac.in/images/Projects/SceneTextUnderstanding/IIIT5K-Word_V3.0.tar.gz\n",
            "Resolving cvit.iiit.ac.in (cvit.iiit.ac.in)... 14.139.82.25\n",
            "Connecting to cvit.iiit.ac.in (cvit.iiit.ac.in)|14.139.82.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://cdn.iiit.ac.in/cdn/cvit.iiit.ac.in/images/Projects/SceneTextUnderstanding/IIIT5K-Word_V3.0.tar.gz [following]\n",
            "--2025-08-29 10:28:45--  https://cdn.iiit.ac.in/cdn/cvit.iiit.ac.in/images/Projects/SceneTextUnderstanding/IIIT5K-Word_V3.0.tar.gz\n",
            "Resolving cdn.iiit.ac.in (cdn.iiit.ac.in)... 14.139.82.19\n",
            "Connecting to cdn.iiit.ac.in (cdn.iiit.ac.in)|14.139.82.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 105861943 (101M) [application/octet-stream]\n",
            "Saving to: ‘IIIT5K.tar.gz’\n",
            "\n",
            "IIIT5K.tar.gz       100%[===================>] 100.96M  13.8MB/s    in 9.0s    \n",
            "\n",
            "2025-08-29 10:28:56 (11.3 MB/s) - ‘IIIT5K.tar.gz’ saved [105861943/105861943]\n",
            "\n",
            "2000 train | 3000 test\n",
            "IIIT5K/train/1009_2.png -> You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocabulary & preprocessing pipeline"
      ],
      "metadata": {
        "id": "fVYGR-wiP09i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary from all labels\n",
        "all_texts = train_labels + test_labels\n",
        "vocab = sorted(set(\"\".join(all_texts)))\n",
        "print(\"Vocab size:\", len(vocab))\n",
        "print(\"Sample vocab:\", vocab[:60])\n",
        "\n",
        "# Char<->index lookups\n",
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)   # 1..N\n",
        "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(),\n",
        "                                           mask_token=None, invert=True)\n",
        "\n",
        "# Image size & label padding\n",
        "IMG_H, IMG_W = 32, 128\n",
        "MAX_LABEL_LEN = max(len(t) for t in all_texts)\n",
        "PAD_TOKEN = 0  # we'll use 0 as padding id (UNK from StringLookup)\n",
        "\n",
        "def encode_sample(img_path, label):\n",
        "    # image\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "    img = tf.image.resize(img, [IMG_H, IMG_W])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    # transpose so time dimension = width\n",
        "    img = tf.transpose(img, [1,0,2])  # (W, H, 1)\n",
        "\n",
        "    # label -> ids\n",
        "    chars = tf.strings.unicode_split(label, \"UTF-8\")\n",
        "    ids = char_to_num(chars)  # 1..N\n",
        "    # pad to MAX_LABEL_LEN with 0\n",
        "    pad = MAX_LABEL_LEN - tf.shape(ids)[0]\n",
        "    ids = tf.pad(ids, [[0, pad]], constant_values=PAD_TOKEN)\n",
        "    return (img, ids)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_images), reshuffle_each_iteration=True)\n",
        "train_ds = train_ds.map(encode_sample, num_parallel_calls=AUTOTUNE)\n",
        "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_ds = test_ds.map(encode_sample, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lvEhPqiP1eu",
        "outputId": "19150369-3a26-4057-dc11-5cdcb3f1d58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 62\n",
            "Sample vocab: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CRNN model (CNN + BiLSTM) that outputs logits"
      ],
      "metadata": {
        "id": "DfeBijrXP6wF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_crnn(num_classes):\n",
        "    image_in = tf.keras.Input(shape=(IMG_W, IMG_H, 1), name=\"image\")\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(image_in)\n",
        "    x = tf.keras.layers.MaxPooling2D(2)(x)     # /2\n",
        "    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(2)(x)     # /4 total\n",
        "\n",
        "    # Now shape is (W/4, H/4, C). Keep time = W/4\n",
        "    new_w = IMG_W // 4\n",
        "    new_h = IMG_H // 4\n",
        "    x = tf.keras.layers.Reshape((new_w, new_h*64))(x)\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True, dropout=0.25))(x)\n",
        "\n",
        "    # logits (no softmax here; CTC expects logits)\n",
        "    logits = tf.keras.layers.Dense(num_classes, name=\"logits\")(x)\n",
        "    return tf.keras.Model(image_in, logits, name=\"crnn_logits\")\n",
        "\n",
        "NUM_CLASSES = len(char_to_num.get_vocabulary()) + 1  # +1 for CTC blank (last index)\n",
        "base_model = build_crnn(NUM_CLASSES)\n",
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "8JObYbFqP7sq",
        "outputId": "21f92995-23b7-4bb5-ebca-2e7900b345be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"crnn_logits\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"crnn_logits\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ image (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m65,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m263,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m164,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ logits (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m520,256\u001b[0m (1.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">520,256</span> (1.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m520,256\u001b[0m (1.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">520,256</span> (1.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Model with CTC train_step"
      ],
      "metadata": {
        "id": "WsVvRyOJQInV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCModel(tf.keras.Model):\n",
        "    def __init__(self, logits_model, blank_index=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.logits_model = logits_model\n",
        "        self.blank_index = blank_index if blank_index is not None else (NUM_CLASSES - 1)\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # data = (images, labels_padded)\n",
        "        images, labels_padded = data\n",
        "\n",
        "        # label lengths = count of non-zero tokens\n",
        "        label_lens = tf.reduce_sum(tf.cast(tf.not_equal(labels_padded, PAD_TOKEN), tf.int32), axis=1)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = self.logits_model(images, training=True)  # (B, T, C)\n",
        "            # time steps\n",
        "            logit_lens = tf.fill([tf.shape(logits)[0]], tf.shape(logits)[1])\n",
        "            # CTC loss (uses logits directly)\n",
        "            loss = tf.nn.ctc_loss(\n",
        "                labels=self._dense_to_sparse(labels_padded, label_lens),\n",
        "                logits=logits,\n",
        "                label_length=label_lens,\n",
        "                logit_length=logit_lens,\n",
        "                logits_time_major=False,\n",
        "                blank_index=self.blank_index\n",
        "            )\n",
        "            loss = tf.reduce_mean(loss)\n",
        "\n",
        "        grads = tape.gradient(loss, self.logits_model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.logits_model.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        images, labels_padded = data\n",
        "        label_lens = tf.reduce_sum(tf.cast(tf.not_equal(labels_padded, PAD_TOKEN), tf.int32), axis=1)\n",
        "        logits = self.logits_model(images, training=False)\n",
        "        logit_lens = tf.fill([tf.shape(logits)[0]], tf.shape(logits)[1])\n",
        "        loss = tf.nn.ctc_loss(\n",
        "            labels=self._dense_to_sparse(labels_padded, label_lens),\n",
        "            logits=logits,\n",
        "            label_length=label_lens,\n",
        "            logit_length=logit_lens,\n",
        "            logits_time_major=False,\n",
        "            blank_index=self.blank_index\n",
        "        )\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    @staticmethod\n",
        "    def _dense_to_sparse(dense_labels, label_lens):\n",
        "        \"\"\"\n",
        "        Convert padded dense labels (B, L) to SparseTensor using provided lengths.\n",
        "        Padding value is 0 and must be excluded.\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(dense_labels)[0]\n",
        "        max_len = tf.shape(dense_labels)[1]\n",
        "        # Build indices for non-pad positions\n",
        "        mask = tf.sequence_mask(label_lens, max_len)  # (B, L) True for real tokens\n",
        "        indices = tf.where(mask)\n",
        "        values = tf.gather_nd(dense_labels, indices)\n",
        "        sparse = tf.SparseTensor(\n",
        "            indices=tf.cast(indices, tf.int64),\n",
        "            values=tf.cast(values, tf.int32),\n",
        "            dense_shape=tf.cast([batch_size, max_len], tf.int64)\n",
        "        )\n",
        "        return sparse\n",
        "\n",
        "# Wrap and compile\n",
        "ctc_model = CTCModel(base_model)\n",
        "ctc_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3))\n"
      ],
      "metadata": {
        "id": "6opUIJ2NQJSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "SnmdNJAsRMSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "history = ctc_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds.take(1),  # quick sanity\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1TLNd0iORM_a",
        "outputId": "ed05a77c-f5b6-4335-e74b-3a15f2fdbad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 41.9588 - val_loss: 21.8490\n",
            "Epoch 2/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 20.2721 - val_loss: 21.7336\n",
            "Epoch 3/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 20.5187 - val_loss: 21.4347\n",
            "Epoch 4/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 20.4471 - val_loss: 21.3372\n",
            "Epoch 5/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 20.0922 - val_loss: 21.2694\n",
            "Epoch 6/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 19.8493 - val_loss: 21.0228\n",
            "Epoch 7/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 19.3314 - val_loss: 20.8666\n",
            "Epoch 8/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 19.4391 - val_loss: 21.2424\n",
            "Epoch 9/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 18.9225 - val_loss: 21.1796\n",
            "Epoch 10/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 18.6809 - val_loss: 21.0521\n",
            "Epoch 11/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 18.5522 - val_loss: 21.6067\n",
            "Epoch 12/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 18.1663 - val_loss: 21.7416\n",
            "Epoch 13/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 18.3009 - val_loss: 22.5091\n",
            "Epoch 14/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 18.2266 - val_loss: 21.3223\n",
            "Epoch 15/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 17.9870 - val_loss: 21.2894\n",
            "Epoch 16/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 17.6848 - val_loss: 21.0214\n",
            "Epoch 17/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 17.2601 - val_loss: 21.0105\n",
            "Epoch 18/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 17.0773 - val_loss: 21.0242\n",
            "Epoch 19/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 17.0810 - val_loss: 19.7775\n",
            "Epoch 20/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 16.8363 - val_loss: 18.9013\n",
            "Epoch 21/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 16.4310 - val_loss: 18.9708\n",
            "Epoch 22/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 16.9779 - val_loss: 18.8124\n",
            "Epoch 23/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 15.8704 - val_loss: 18.6991\n",
            "Epoch 24/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 16.0474 - val_loss: 19.3325\n",
            "Epoch 25/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 15.9929 - val_loss: 20.7347\n",
            "Epoch 26/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 15.3052 - val_loss: 19.8614\n",
            "Epoch 27/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 14.8379 - val_loss: 19.1533\n",
            "Epoch 28/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 14.7206 - val_loss: 18.7877\n",
            "Epoch 29/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 14.3455 - val_loss: 18.1084\n",
            "Epoch 30/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 13.7468 - val_loss: 20.0661\n",
            "Epoch 31/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 13.5301 - val_loss: 18.1763\n",
            "Epoch 32/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 13.0659 - val_loss: 17.8329\n",
            "Epoch 33/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 12.6080 - val_loss: 18.1603\n",
            "Epoch 34/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 12.6941 - val_loss: 17.3882\n",
            "Epoch 35/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 12.0693 - val_loss: 19.1137\n",
            "Epoch 36/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 11.9028 - val_loss: 17.5923\n",
            "Epoch 37/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 11.6378 - val_loss: 18.4074\n",
            "Epoch 38/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 11.3382 - val_loss: 19.0908\n",
            "Epoch 39/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 10.7884 - val_loss: 15.9481\n",
            "Epoch 40/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 10.3755 - val_loss: 17.2904\n",
            "Epoch 41/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 10.0982 - val_loss: 17.0705\n",
            "Epoch 42/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.7593 - val_loss: 15.6268\n",
            "Epoch 43/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.1665 - val_loss: 16.1955\n",
            "Epoch 44/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.8095 - val_loss: 14.9496\n",
            "Epoch 45/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.7971 - val_loss: 16.5523\n",
            "Epoch 46/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.4373 - val_loss: 14.6100\n",
            "Epoch 47/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.3505 - val_loss: 16.7197\n",
            "Epoch 48/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.6023 - val_loss: 14.4806\n",
            "Epoch 49/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.3327 - val_loss: 15.7549\n",
            "Epoch 50/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.9990 - val_loss: 13.5898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference helper (greedy CTC decode) + metrics (Accuracy & CER)"
      ],
      "metadata": {
        "id": "RSMxemflRTf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A separate inference model: image -> logits -> softmax\n",
        "image_infer = base_model.input\n",
        "logits_out  = base_model.output\n",
        "infer_model = tf.keras.Model(image_infer, logits_out)\n",
        "\n",
        "def greedy_decode(logits, blank_index=NUM_CLASSES-1):\n",
        "    \"\"\"\n",
        "    Greedy CTC decode on numpy logits: argmax per time step, then collapse repeats and drop blanks.\n",
        "    Returns list[str] of decoded words.\n",
        "    \"\"\"\n",
        "    probs = tf.nn.softmax(logits, axis=-1).numpy()\n",
        "    argmax = np.argmax(probs, axis=-1)  # (B, T)\n",
        "    decoded = []\n",
        "    for seq in argmax:\n",
        "        prev = None\n",
        "        result = []\n",
        "        for idx in seq:\n",
        "            if idx == blank_index:  # blank\n",
        "                prev = None\n",
        "                continue\n",
        "            if idx == prev:         # collapse repeats\n",
        "                continue\n",
        "            result.append(idx)\n",
        "            prev = idx\n",
        "        # map ids -> chars\n",
        "        chars = [num_to_char(tf.constant(i)).numpy().decode(\"utf-8\") for i in result]\n",
        "        decoded.append(\"\".join(chars))\n",
        "    return decoded\n",
        "\n",
        "def ids_to_text_batch(padded_ids):\n",
        "    texts = []\n",
        "    for row in padded_ids:\n",
        "        row = tf.gather(row, tf.where(tf.not_equal(row, PAD_TOKEN)))  # remove pads\n",
        "        txt = tf.strings.reduce_join(num_to_char(tf.cast(tf.squeeze(row, axis=1), tf.int32)))\n",
        "        texts.append(txt.numpy().decode(\"utf-8\"))\n",
        "    return texts\n",
        "\n",
        "def char_error_rate(pred, truth):\n",
        "    \"\"\"Simple CER: normalized Levenshtein distance per pair, averaged.\"\"\"\n",
        "    def lev(a,b):\n",
        "        dp = np.zeros((len(a)+1, len(b)+1), dtype=np.int32)\n",
        "        dp[:,0] = np.arange(len(a)+1)\n",
        "        dp[0,:] = np.arange(len(b)+1)\n",
        "        for i in range(1, len(a)+1):\n",
        "            for j in range(1, len(b)+1):\n",
        "                cost = 0 if a[i-1]==b[j-1] else 1\n",
        "                dp[i,j] = min(dp[i-1,j]+1, dp[i,j-1]+1, dp[i-1,j-1]+cost)\n",
        "        return dp[len(a),len(b)]\n",
        "    cers = []\n",
        "    for p,t in zip(pred, truth):\n",
        "        denom = max(1, len(t))\n",
        "        cers.append( lev(p,t) / denom )\n",
        "    return float(np.mean(cers))\n",
        "\n",
        "# Evaluate on the full test set\n",
        "total, correct = 0, 0\n",
        "all_pred, all_true = [], []\n",
        "\n",
        "for batch in test_ds:\n",
        "    imgs, lbls = batch\n",
        "    logits = infer_model(imgs, training=False)\n",
        "    pred_texts = greedy_decode(logits)\n",
        "    true_texts = ids_to_text_batch(lbls)\n",
        "\n",
        "    all_pred.extend(pred_texts)\n",
        "    all_true.extend(true_texts)\n",
        "    for p,t in zip(pred_texts, true_texts):\n",
        "        correct += int(p == t)\n",
        "        total += 1\n",
        "\n",
        "word_acc = 100.0 * correct / total\n",
        "cer = char_error_rate(all_pred, all_true)\n",
        "print(f\"Test Word Accuracy: {word_acc:.2f}%  |  CER: {cer:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6ATDhKRRUCD",
        "outputId": "95eaf1d1-9a34-4a07-caf6-f80092f521ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Word Accuracy: 10.47%  |  CER: 0.5952\n"
          ]
        }
      ]
    }
  ]
}